apiVersion: v1
kind: Service
metadata:
  name: dm-monitor-backend
  #namespace: app
  labels:
    app: dm-monitor-backend
spec:
  #clusterIP: None
  selector:
    app: dm-monitor-backend
  # to make it accessible outside of cluster
  #type: NodePort
  ports:
    - name: main
      port: 5130
      protocol: TCP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dm-monitor-backend
  #namespace: app
  labels:
    app: dm-monitor-backend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: dm-monitor-backend
  template:
    metadata:
      labels:
        app: dm-monitor-backend
    spec:
      imagePullSecrets:
        - name: registry-credentials
      containers:
      - name: dm-monitor-backend
        image: "TILT_PLACEHOLDER:imageURL_monitorBackend"
        resources:
          requests:
            memory: 500Mi
          limits:
            #cpu: "900m" # commented atm, due to limits apparently causing slowdown, even if limit not reached (see: https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits)
            # if it ends up using more than this, it is likely a memory leak; kill and restart should restore regular performance
            memory: 1000Mi
        livenessProbe:
          httpGet:
            path: /health-check
            port: 5130
          initialDelaySeconds: 10999999 # mode: profiling
          #initialDelaySeconds: 20 # mode: normal
          periodSeconds: 10
          timeoutSeconds: 3
        env:
        - name: DB_VENDOR
          value: "postgres"
        - name: DB_ADDR
          valueFrom: { secretKeyRef: { name: debate-map-pguser-admin, key: host } }
        - name: DB_PORT
          valueFrom: { secretKeyRef: { name: debate-map-pguser-admin, key: port } }
        - name: DB_DATABASE
          valueFrom: { secretKeyRef: { name: debate-map-pguser-admin, key: dbname } }
        - name: DB_USER
          valueFrom: { secretKeyRef: { name: debate-map-pguser-admin, key: user } }
        - name: DB_PASSWORD
          valueFrom: { secretKeyRef: { name: debate-map-pguser-admin, key: password } }
        - name: PROXY_ADDRESS_FORWARDING
          value: "true"
        # just reuse the db-password as the admin-key for now
        - name: MONITOR_BACKEND_ADMIN_KEY
          valueFrom: { secretKeyRef: { name: debate-map-pguser-admin, key: password } }

# give monitor-backend various kubernetes-api permissions, within its own namespace "default"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: role-for-dm-monitor-backend
  namespace: default
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: [
    "list",
    "get",
    #"watch",
    "delete"
  ]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: role-binding-for-dm-monitor-backend
  namespace: default
subjects:
  - kind: ServiceAccount
    name: default
roleRef:
  kind: Role
  name: role-for-dm-monitor-backend
  apiGroup: rbac.authorization.k8s.io

# give monitor-backend various kubernetes-api permissions, *across namespaces*
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole # note that we use "ClusterRole" instead of just "Role", so granted permissions can work across namespaces
metadata:
  name: cluster-role-for-dm-monitor-backend
  namespace: default
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding # note: using ClusterRoleBinding (as matching above)
metadata:
  name: cluster-role-binding-for-dm-monitor-backend
  namespace: default
subjects:
  - kind: ServiceAccount
    name: default
    namespace: default # this also becomes required
roleRef:
  kind: ClusterRole # note: using ClusterRole (as matching above)
  name: cluster-role-for-dm-monitor-backend
  apiGroup: rbac.authorization.k8s.io