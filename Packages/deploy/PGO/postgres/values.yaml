---
# For a full explanation of how to set up the custom resource, please refer to
# the documentation:
#    https://access.crunchydata.com/documentation/postgres-operator/v5/

###########
# General #
###########

# name is the name of the cluster. This defaults to the name of the Helm
# release.
name: debate-map

# postgresVersion sets the version to deploy. This version number needs to be
# available as one of the "RELATED_IMAGE_POSTGRES_..." images as part of the PGO
# installation if you want to deploy the image without setting the "postgres"
# image variable. This value is required.
#postgresVersion: 14
#postgresVersion: 13
postgresVersion: 15

# postGISVersion if sets and coupled with a PostGIS enabled container, enables
# PostGIS. This version number needs to be available as one of the
# "RELATED_IMAGE_POSTGRES_..." images as part of the PGO installation if you
# want to deploy the image without setting the "postgres" image variable.
# postGISVersion: 3.1

# NOTE: pgBackRest is enabled by default. It must be set in
# "RELATED_IMAGE_PGBACKREST" on the PGO deployment, otherwise you will need to
# override the "pgBackRest" image.

# pgBouncerReplicas sets the number of pgBouncer instances to deploy. The
# default is 0. You need to set this to at least 1 to deploy pgBouncer or set
# "pgBouncerConfig". Setting "pgBouncerConfig" will override the value of
# pgBouncerReplicas. The "RELATED_IMAGE_PGBOUNCER" in the PGO deployment must be
# set if you want to enable this without explicitly setting "pgBouncer".
# pgBouncerReplicas: 1

# monitoring enables the ability to monitor the Postgres cluster through a
# metrics exporter than can be scraped by Prometheus. This defaults to the value
# below.
# monitoring: false

###################
# Image Overrides #
###################

# imagePostgres can be a Postgres or GIS-enabled Postgres image. This defaults to the
# below value. "postgresVersion" needs to match the version of Postgres that is
# used here. If using the GIS-enabled Postgres image, you need to ensure
# "postGISVersion" matches the version of PostGIS used.
# imagePostgres: registry.developers.crunchydata.com/crunchydata/crunchy-postgres:ubi8-13.8-1

# imagePgBackRest is the pgBackRest backup utility image. This defaults to the
# below value.
# imagePgBackRest: registry.developers.crunchydata.com/crunchydata/crunchy-pgbackrest:ubi8-2.41-2

# imagePgBouncer is the image for the PgBouncer connection pooler. This defaults
# to the below value.
# imagePgBouncer: registry.developers.crunchydata.com/crunchydata/crunchy-pgbouncer:ubi8-1.17-5

# imageExporter is the image name for the exporter used as a part of monitoring.
# This defaults to the value below.
# imageExporter: registry.developers.crunchydata.com/crunchydata/crunchy-postgres-exporter:ubi8-5.3.0-0

###########################
# Basic Postgres Settings #
###########################

# instanceName lets you set the name of your instances. This defaults to
# the value below. Setting "instances" overrides this value.
# instanceName: instance1

# instanceSize sets the size of the volume that contains the data. This defaults
# to the value below. Settings "instances" overrides this value.
instanceSize: 10000Mi

# V-NOTE on instanceSize above + the 3 related sizes in contents below:
# ==========
# * You might hit a situation where you want to increase the sizes slightly, eg. to fix an urgent out-of-space issue.
# * When I did X.1Gi, that seemed to work in past. (didn't really check logs for errors though)
# * Recently when I tried X.1Gi, I checked logs and noticed an error/warning of "size not being an integer" or something.
# * So then I tried entering an exact bytes value (to avoid fractions theoretically possible from 10% of Gi), that avoided the integer issue, but...
#   ...seemed to result in a persistent-volume of X+1Gi, rather than X.1Gi. (the PVC sizes appeared as expected though) 

# instanceMemory sets the memory limit for the Postgres instances. This defaults
# to no limit being set, but an example value is set below. Settings "instances"
# overrides this value.
# instanceMemory: 2Gi

# instanceCPU sets the CPU limit for the Postgres instances. This defaults to
# no limit being set, but an example value is set below. Setting "instances"
# overrides this value.
# instanceCPU: 1000m

# instanceReplicas lets you set the total number of Postgres replicas. This
# defaults to the value below. More than on replica enables high availability
# (HA). Settings "instances" overrides this value.
# instanceReplicas: 1

##############################
# Advanced Postgres Settings #
##############################

# instances allows you to define one or more Postgres instance sets. By default,
# PGO will only deploy a single instance. Each instance set has similar
# characteristics to the other instances in the set, e.g. storage size, resource
# etc. You can have multiple replicas within an instance set.
#
# This allows you to fully customize the topology of your Postgres instances.
#
# For example, to set up an instance set with HA (due to the default pod
# topology spread constraints)
#
# instances:
#   - name: pgha1
#     replicas: 2
#     dataVolumeClaimSpec:
#       accessModes:
#       - "ReadWriteOnce"
#       resources:
#         requests:
#           storage: 1Gi
# instances: {}

# port sets the port that Postgres listens on. Defaults to 5432.
# port: 5432

# patroni lets you set the Patroni configuration for the Postgres cluster.
# for example, to set up synchronous replication:
# patroni:
#   dynamicConfiguration:
#     synchronous_mode: true
#     postgresql:
#       parameters:
#         synchronous_commit: "on"
patroni:
  dynamicConfiguration:
    postgresql:
      #parameters:
      #  max_parallel_workers: 2
      #  max_worker_processes: 2
      #  shared_buffers: 1GB
      #  work_mem: 2MB

      # values for parameters based on [https://pgtune.leopard.in.ua] and [https://stackoverflow.com/a/32584211]
      # NOTE: To apply these changes:
      # 1) Make sure kubectl/docker-desktop has the right cluster set. (use docker-desktop's tray-icon)
      # 2) Run this in repo root: `kubectl apply -k Packages/deploy/PGO/postgres`
      # 3) This "shouldn't" be necessary, but atm I've found that I need to kill the "debate-map-instance1-XXX" pod for changes to be applied (at least quickly); after doing so, the pod will restart in a half minute or so.
      # 4) Confirm that changes were applied, by using Lens to open terminal in the "debate-map-instance1-XXX" pod, running `psql`, then running: `SHOW max_connections;`
      parameters:
        # for 15gb node
        max_connections: 300 # default: 100

        # for 30gb node
        # max_connections: 1000 # default: 100
        # shared_buffers: 5GB # default: 8MB/128MB
        # maintenance_work_mem: 1GB # default: 64MB
        # effective_cache_size: 10GB # default: 4GB
        # #work_mem: 10MB # default: 4MB # not increasing this atm, as it's "per connection", and we have so many

        # to try to reduce occurence of failures when committing serializable transactions (each is x10 default)
        # max_locks_per_transaction: 640
        # max_pred_locks_per_transaction: 640
        # max_pred_locks_per_relation: -20
        # max_pred_locks_per_page: 20
      pg_hba:
        - host all all 0.0.0.0/0 md5

# users sets any custom Postgres users and databases that they have  access to
# as well as any permissions assoicated with the user account.
users:
  - name: admin
    databases:
      - debate-map
    options: "SUPERUSER"

# dataSource specifies a data source for bootstrapping a Postgres cluster. # venryx: ie. for restoring backups (recommended approach atm)
dataSource_DISABLED: # rename "dataSource_DISABLED" -> "dataSource" AND uncomment the relevant section below, to enable the backup-restoration config (see dm-readme module [pgbackrest-restore])
  postgresCluster___INCLUDE_IF_devCluster:
    # intentionally empty atm
  postgresCluster___INCLUDE_IF_prodCluster:
    # postgresCluster:
    #   clusterName: debate-map
    #   repoName: repo2
    #   options:
    #   # use this to restore to a base-backup, without wal-archive replaying (modify "set" to the base-backup folder-name seen in the cloud-bucket)
    #   # NOTE: This approach doesn't currently work, unless you add a workaround. See here: https://github.com/CrunchyData/postgres-operator/issues/1886#issuecomment-907784977
    #   - --set 20221218-030022F_20221220-031024D
    #   - --type=immediate
    #   #- --target-action=promote
    #   # use this to restore to a specific point-in-time, with wal-archive replaying (modifying "target" to the time you want to restore to, with specified timezone [UTC recommended])
    #   # - --type=time
    #   # - --target="2021-09-01 07:42:06+00"

# customTLSSecret references a Secret that contains the relevant information for
# bringing external TLS artifacts to a PostgreSQL cluster. This provides the
# TLS for the cluster itself.
# customTLSSecret: {}

# customReplicationTLSSecret references a Secret that contains the relevant
# information for bringing external TLS artifacts to a PostgreSQL cluster. This
# provides the information for the replication user.
# customReplicationTLSSecret: {}

# databaseInitSQL referencs a ConfigMap that contains a SQL file that should be
# run a cluster bootstrap.
# databaseInitSQL:
#   name: bootstrap-sql
#   key: bootstrap.sql

# standby sets whether or not to run this as a standby cluster. Both of the
# values below are required to enable a standby cluster. Setting "enabled" to
# "true" eunables the standby cluster while "repoName" points to a pgBackRest
# archive to replay WAL files from.
# standby:
#   enabled: false
#   repoName: repo1

# shutdown when set scales the entire workload to zero. By default this is not
# set.
# shutdown: true

#################################
# Backups / pgBackRest Settings #
#################################

# backupsSize sets the storage size of the backups to a volume in Kubernetes.
# can be overridden by "pgBackRestConfig", if set. Defaults to the value below.
# backupsSize: 1Gi

# s3 allows for AWS S3 or an S3 compatible storage system to be used for
# backups. This allows for a quick setup with S3; if you need more advanced
# setup, use pgBackRestConfig.
# s3:
#   # bucket specifies the S3 bucket to use,
#   bucket: ""
#   # endpoint specifies the S3 endpoint to use.
#   endpoint: ""
#   # region specifies the S3 region to use. If your S3 storage system does not
#   # use "region", fill this in with a random vaule.
#   region: ""
#   # key is the S3 key. This is stored in a Secret.
#   key: ""
#   # keySecret is the S3 key secret. This is tored in a Secret.
#   keySecret: ""
#   # encryptionPassphrase is an optional parameter to enable encrypted backups
#   # with pgBackRest. This is encrypted by pgBackRest and does not use S3's
#   # built-in encrpytion system.
#   encryptionPassphrase: ""

# gcs allows for Google Cloud Storage (GCS) to be used for backups. This allows
# for a quick setup with GCS; if you need a more advanced setup, use
# "pgBackRestConfig".
# gcs:
#   # bucket is the name of the GCS bucket that the backups will be stored in.
#   bucket: ""
#   # key is a multi-line string that contains the GCS key, which is a JSON
#   # structure.
#   key: |
#     {}

# azure allows for Azure Blob Storage to be used for backups. This allows
# for a quick setup with Azure Blob Storage; if you need a more advanced setup,
# use "pgBackRestConfig".
# azure:
#   # account is the name of the Azure account to be used.
#   account: ""
#   # key is the Secret key used associated with the Azure acount.
#   key: ""
#   # container is the Azure container that the backups will be stored in.
#   container: ""

# multiBackupRepos allows for backing up to multiple repositories. This is
# effectively uses the "quickstarts" for each of the backup types (volume, s3,
# gcs, azure). You can have any permutation of these types. You can set up to 4.
# can be overwritten by "pgBackRestConfig".
#
# You can't set "multiBackupRepos" and any of the individual quickstarts at the
# same time. "multiBackupRepos" will take precedence.
#
# Below is an example that enables one of each backup type. Note all of the
# available quickstart options are presented below; please see the backup types
# if you want to see how each option works.
# v-note: Why is this key set, even though we're using the pgBackRestConfig key (which overwrites its values in the resultant postgres.yaml)?
# ... Because: This key must be set in order for the "debate-map-pgbackrest-secret" resource to be generated by `pgbackrest-secret.yaml`
multiBackupRepos:
- volume:
    #backupsSize: [this config field is commented, since it gets overridden by the pgBackRestConfig.repos[0].volume.[...].storage subfield anyway]
- gcs:
    bucket: "TILT_PLACEHOLDER:bucket_uniformPrivate_name"
    key: |
      TILT_PLACEHOLDER:gcsKeyAsString
# - s3:
#     bucket: ""
#     endpoint: ""
#     region: ""
#     key: ""
#     keySecret: ""
# - azure:
#     account: ""
#     key: ""
#     container: ""

# pgBackRestConfig allows for the configuration of every pgBackRest option
# except for "image", which is set by "pgBackRest".
pgBackRestConfig:
  repoHost:
    dedicated: {}
  global:
    # v-added
    # for now, we just want to get the repo-pvc cleared out, so set retention (in the in-cluster "repo1" backup pvc) to only 1 full backup
    # (this will let the old full-backup at PVC recreation become "expired", letting all the WAL files between then and the new full-backup get removed)
    repo1-retention-full: "1"
    repo1-retention-full-type: count

    # set path to save backups within the target google-cloud-storage bucket
    repo2-path: /db-backups-pgbackrest
  repos:
  - name: repo1
    volume:
      volumeClaimSpec:
        accessModes:
        - "ReadWriteOnce"
        resources:
          requests:
            storage: 15000Mi
    # NOTE: These local backups may feel unnecessary, but THEY ARE NECESSARY for old WAL segments to get cleaned up.
    # (pgbackrest's standard config only expires WAL segments older than the last full backup, and that will only happen once at pgo init unless you set a schedule here!)
    schedules:
      # at 3am, each Saturday (cron schedule syntax: https://crontab.guru)
      full: "0 0 * * 6"
  - name: repo2
    ___INCLUDE_PARENT_IF_gcsOn: true
    gcs:
      bucket: "TILT_PLACEHOLDER:bucket_uniformPrivate_name"
    schedules:
      # at 3am, each Sunday (cron schedule syntax: https://crontab.guru)
      full: "0 3 * * 0"
      # at 3:10am, each day (cron schedule syntax: https://crontab.guru)
      differential: "10 3 * * *"
  configuration___INCLUDE_IF_gcsOn:
  - secret:
      name: debate-map-pgbackrest-secret
  # configuration for the next manual backup to be triggered (see deploy/pg-backups guide-module for more info)
  manual___INCLUDE_IF_gcsOn:
    repoName: repo2
    options:
    - --type=full

  # configuration for the next restore to be triggered # commented; now set using the restoreDBBackup_prep script
  # restore:
  #   enabled: true
  #   repoName: repo2
  #   options:
  #   - --set 20210828-044420F
  #   - --type=time
  #   - --target="2021-08-28 04:44:20 UTC"

  # restore: {
  #   enabled: true,
  #   repoName: "repo2",
  #   options: [
  #     "--delta",
  #     "--force",
  #     "--set 20210828-074206F"
  #   ]
  # }

################################
# Pooling / pgBouncer Settings #
################################

# pgBouncerConfig sets all of the pgBouncer portion of the spec except for
# image. To set image, you need to set the "pgBouncer" setting.
# pgBouncerConfig: {}

#######################
# Monitoring Settings #
#######################

# monitoringConfig sets all of the monitoring portion of the spec except for the
# image. To set the image, which also enables monitoring, you need to set the
# "monitoring" setting.
# monitoringConfig: {}

#######################
# Kubernetes Settings #
#######################

# metadata contains any metadata that should be applied to all PGO managed
# objects in this Postgres cluster. This includes "annotations" and "labels" as
# subkeys.
metadata:
  annotations:
    # make-so the user-secret can be mirrored to the "app" namespace (see user-secret-mirror.yaml for the annotation on the "pulling" end)
    reflector.v1.k8s.emberstack.com/reflection-allowed: "true"
    #reflector.v1.k8s.emberstack.com/reflection-allowed-namespaces: "app"
    reflector.v1.k8s.emberstack.com/reflection-allowed-namespaces: "default"
    #reflector.v1.k8s.emberstack.com/reflection-auto-enabled: "true"
    #reflector.v1.k8s.emberstack.com/reflection-auto-namespaces: "app"

# service customizes the Service that exposes the Postgres primary.
# service: {}

# imagePullPolicy sets the pull policy for all the images. This defaults to
# the Kubernetes heuristic:
# https://kubernetes.io/docs/concepts/containers/images/#imagepullpolicy-defaulting
# imagePullPolicy: IfNotPresent

# imagePullSecrets references Secrets that credentials for pulling image from
# private repositories
# imagePullSecrets: []

# supplementalGroups sets any group IDs that should be assigned to
# Pods, particularly around file system contraints within a system
# supplementalGroups: []

# disableDefaultPodScheduling if set to true, will disable any of the default
# scheduling constraints for Pods, such as the default Pod Topology Spread
# Constraints. If set to false or unset, the default scheduling constraints will
# be used in addition to any customizations that are added in.
# disableDefaultPodScheduling: false

# openshift can set explicitly if this is an OpenShift cluster, or a cluster
# that uses a SecurityContextConstraint. This usually does not need to be set,
# but you may want to explicitly set it to "false" when using a SCC like
# "anyuid"
# v-uncommented (needed to fix bug in template/postgres.yaml apparently, due to use of "eq" operator)
openshift: false
